{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/alexandrosstergiou/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from skimage import color, exposure, transform\n",
    "from PIL import Image \n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data, img_as_float\n",
    "from skimage import exposure\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Convolution2D \n",
    "from keras.layers import Input, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.utils import np_utils \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def analyse_images(imgs_paths):\n",
    "    \n",
    "    data = []\n",
    "    i = 0\n",
    "    for img_path in imgs_paths:\n",
    "        img_class = int(img_path.split('/')[-2])\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        #If image has width and height that are not equal\n",
    "        #or overall size is not of 48x48\n",
    "        \n",
    "        size = 48,48\n",
    "        img = Image.open(img_path)\n",
    "        img = img.thumbnail(size, Image.ANTIALIAS)\n",
    "        os.remove(img_path)\n",
    "        img.save(img_path, \"JPEG\")\n",
    "        \"\"\"\n",
    "        \n",
    "        img = io.imread(img_path)\n",
    "        \n",
    "\n",
    "        # Histogram\n",
    "        img_h = exposure.equalize_hist(img)\n",
    "        \n",
    "        data.append([img_h,img_class])\n",
    "        \n",
    "        i = i+1\n",
    "        \n",
    "        #Print every 10000 images\n",
    "        if ((i % 10000)== 0):\n",
    "            print (\"Images processed: \")+str(i)\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrosstergiou/anaconda/lib/python2.7/site-packages/skimage/exposure/exposure.py:63: UserWarning: This might be a color image. The histogram will be computed on the flattened image. You can instead apply this function to each color channel.\n",
      "  warn(\"This might be a color image. The histogram will be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images processed: 10000\n",
      "Images processed: 20000\n",
      "Images processed: 30000\n",
      "Images processed: 40000\n",
      "Images processed: 50000\n",
      "Images processed: 60000\n",
      "Images processed: 70000\n",
      "Images processed: 80000\n",
      "Images processed: 90000\n",
      "Images processed: 100000\n",
      "Images processed: 110000\n",
      "Images processed: 120000\n",
      "Images processed: 130000\n",
      "Images processed: 140000\n",
      "Images processed: 150000\n",
      "Images processed: 160000\n",
      "Images processed: 170000\n",
      "Images processed: 180000\n",
      "Images processed: 190000\n",
      "Images processed: 200000\n"
     ]
    }
   ],
   "source": [
    "directory = 'SGTSD/Images/'\n",
    "paths = []\n",
    "number_signs = 0\n",
    "\n",
    "for sub_dir in os.listdir(directory):\n",
    "    sd = directory+sub_dir+'/'\n",
    "    if (sub_dir != \".DS_Store\"):\n",
    "        number_signs = number_signs+1\n",
    "        for files in os.listdir(sd):\n",
    "            if (files.endswith(\".csv\")==False):\n",
    "                paths.append(directory+sub_dir+'/'+files)\n",
    "\n",
    "\n",
    "\n",
    "np.random.shuffle(paths)\n",
    "data = analyse_images(paths)\n",
    "elements = []\n",
    "classes = []\n",
    "for d in data:\n",
    "    elements.append(d[0])\n",
    "    classes.append(d[1])\n",
    "\n",
    "    \n",
    "direct = 'val_set/'\n",
    "val_paths = []\n",
    "for sub_dir in os.listdir(direct):\n",
    "    sd = direct+sub_dir+'/'\n",
    "    if (sub_dir != \".DS_Store\"):\n",
    "        for files in os.listdir(sd):\n",
    "            if (files.endswith(\".csv\")==False) and (files.endswith(\".DS_Store\")==False):\n",
    "                val_paths.append(direct+sub_dir+'/'+files)\n",
    "                \n",
    "np.random.shuffle(val_paths)\n",
    "val_data = analyse_images(val_paths)\n",
    "val_elements = []\n",
    "val_classes = []\n",
    "for vd in val_data:\n",
    "    val_elements.append(vd[0])\n",
    "    val_classes.append(vd[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model(height,width,depth,number_signs):\n",
    "    \n",
    "    \n",
    "    inp = Input(shape=(height, width, depth))\n",
    "    \n",
    "    act= keras.layers.advanced_activations.LeakyReLU(alpha=0.001)\n",
    "    #act = keras.layers.advanced_activations.ELU(alpha=0.001)\n",
    "    conv_1 = Convolution2D(32, (3, 3), padding='same', activation=act)(inp)\n",
    "    conv_2 = Convolution2D(32, (3, 3), padding='same', activation=act)(conv_1)\n",
    "    \n",
    "    pool_1 = MaxPooling2D((2, 2), data_format=\"channels_last\")(conv_2)\n",
    "    drop_1 = Dropout(0.25)(pool_1)\n",
    "\n",
    "    \n",
    "    conv_3 = Convolution2D(64, (3, 3), padding='same', activation=act)(drop_1)\n",
    "    conv_4 = Convolution2D(64, (3, 3), padding='same', activation=act)(conv_3)\n",
    "\n",
    "    pool_2 = MaxPooling2D((2, 2), data_format=\"channels_last\")(conv_4)\n",
    "    drop_2 = Dropout(0.25)(pool_2)\n",
    "    \n",
    "    conv_5 = Convolution2D(128, (3, 3), padding='same', activation=act)(drop_2)\n",
    "    conv_6 = Convolution2D(128, (3, 3), padding='same', activation=act)(conv_5)\n",
    "\n",
    "    pool_3 = MaxPooling2D((2, 2), data_format=\"channels_last\")(conv_6)\n",
    "    drop_3 = Dropout(0.25)(pool_3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    flat = Flatten()(drop_3)\n",
    "    hidden = Dense(256, activation=act)(flat)\n",
    "    drop_4 = Dropout(0.5)(hidden)\n",
    "    out = Dense(number_signs, activation='softmax')(drop_4)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrosstergiou/anaconda/lib/python2.7/site-packages/keras/activations.py:89: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                12850     \n",
      "=================================================================\n",
      "Total params: 1,479,762\n",
      "Trainable params: 1,479,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model(48,48,3,number_signs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 2500 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 708s - loss: 0.6569 - acc: 0.8144 - val_loss: 2.2309 - val_acc: 0.5548\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 678s - loss: 0.0315 - acc: 0.9906 - val_loss: 2.7906 - val_acc: 0.5392\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 676s - loss: 0.0298 - acc: 0.9920 - val_loss: 1.6743 - val_acc: 0.6368\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 676s - loss: 0.0153 - acc: 0.9962 - val_loss: 2.0581 - val_acc: 0.6332\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 699s - loss: 0.0250 - acc: 0.9946 - val_loss: 2.2115 - val_acc: 0.6164\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 700s - loss: 0.0182 - acc: 0.9958 - val_loss: 2.9314 - val_acc: 0.6216\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 701s - loss: 0.0366 - acc: 0.9937 - val_loss: 2.5154 - val_acc: 0.6424\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 678s - loss: 0.0164 - acc: 0.9967 - val_loss: 3.2921 - val_acc: 0.6120\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 692s - loss: 0.0251 - acc: 0.9958 - val_loss: 2.9740 - val_acc: 0.6964\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 718s - loss: 0.0274 - acc: 0.9958 - val_loss: 3.5945 - val_acc: 0.6640\n",
      "Epoch 11/30\n",
      "44384/50000 [=========================>....] - ETA: 78s - loss: 0.0369 - acc: 0.9957"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epochs = 30\n",
    "\n",
    "\n",
    "X_train = np.array(elements, dtype='float32')\n",
    "Y_train = np.eye(number_signs, dtype='uint8')[classes]\n",
    "\n",
    "X_val = np.array(val_elements, dtype='float32')\n",
    "Y_val = np.eye(number_signs, dtype='uint8')[val_classes]\n",
    "\n",
    "history = model.fit(X_train[:50000], Y_train[:50000],batch_size=batch_size,epochs=nb_epochs, validation_data=(X_val,Y_val))\n",
    "\n",
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('CNN_1-accuracy.png')\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('CNN_1-loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "orig_stdout = sys.stdout\n",
    "f = open('Model_Summary.txt', 'w')\n",
    "sys.stdout = f\n",
    "print(model.summary())\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_stdout = sys.stdout\n",
    "f = open('History.txt', 'w')\n",
    "sys.stdout = f\n",
    "print(history.history)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
