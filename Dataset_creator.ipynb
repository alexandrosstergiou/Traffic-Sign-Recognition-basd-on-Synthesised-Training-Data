{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage import color, exposure, transform\n",
    "from PIL import Image, ImageChops, ImageDraw, ImageOps, ImageFilter, ImageStat, ImageEnhance \n",
    "import imutils\n",
    "import argparse\n",
    "import ntpath\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import math\n",
    "from blend_modes import blend_modes\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_paths(directory):\n",
    "    paths = []\n",
    "    for files in os.listdir(directory):\n",
    "        if (files != \".DS_Store\"):\n",
    "            paths.append(directory+'/'+files)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_borders(img,pix):\n",
    "    borders = []    \n",
    "    for y in range(0,img.size[1]):\n",
    "        found = False\n",
    "        has_grey = False\n",
    "        \n",
    "        for x in range(1,img.size[0]):\n",
    "\n",
    "            r = pix[x,y][0]\n",
    "            g = pix[x,y][1]\n",
    "            b = pix[x,y][2]\n",
    "                \n",
    "            prev_r = pix[x-1,y][0]\n",
    "            prev_g = pix[x-1,y][1]\n",
    "            prev_b = pix[x-1,y][2]\n",
    "            \n",
    "            r_g = abs(r-g)\n",
    "            r_b = abs(r-b)\n",
    "            g_b = abs(g-b)\n",
    "            \n",
    "            if (r_g<=15 and r_b<=15 and g_b<=15):\n",
    "                has_grey = True\n",
    "\n",
    "                \n",
    "            if ((abs(prev_r-r)>=20) or (abs(prev_g-g)>=20) or (abs(prev_b-b)>=20)):\n",
    "                    \n",
    "                for i in range(0,x):\n",
    "                    borders.append([i,y])\n",
    "                found = True\n",
    "                break   \n",
    "            \n",
    "        if ((not found)and(has_grey)):\n",
    "            for i in range(0,img.size[0]-1):\n",
    "                borders.append([i,y])  \n",
    "              \n",
    "        for x in range(img.size[0]-1,1,-1):\n",
    "                \n",
    "            r = pix[x,y][0]\n",
    "            g = pix[x,y][1]\n",
    "            b = pix[x,y][2]\n",
    "                \n",
    "            prev_r = pix[x-1,y][0]\n",
    "            prev_g = pix[x-1,y][1]\n",
    "            prev_b = pix[x-1,y][2]\n",
    "                \n",
    "            if ((abs(prev_r-r)>=20) or (abs(prev_g-g)>=20) or (abs(prev_b-b)>=20)):\n",
    "                    \n",
    "                for i in range(x,img.size[0]-1):\n",
    "                    borders.append([i,y])\n",
    "                break\n",
    "                    \n",
    "    return borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manipulate_images(paths):\n",
    "    \n",
    "    for image_path in paths:\n",
    "        \n",
    "        \n",
    "        \n",
    "        img = Image.open(image_path)\n",
    "        pix = img.load()\n",
    "        \n",
    "        borders = find_borders(img,pix)\n",
    "         \n",
    "        \n",
    "        image = cv2.imread(image_path, -1)\n",
    "        \n",
    "        b_channel, g_channel, r_channel = cv2.split(image)\n",
    "        alpha_channel = np.ones(b_channel.shape, dtype=b_channel.dtype) * 255\n",
    "        image_RGBA = cv2.merge((b_channel, g_channel, r_channel, alpha_channel))\n",
    "        \n",
    "        height, width, channels = image.shape\n",
    "        \n",
    "        #Deleting white perimeter of shape\n",
    "        for i in range(0,img.size[0]-1):\n",
    "            image_RGBA[0,i][3] = 0\n",
    "            image_RGBA[img.size[1]-1,i][3] = 0\n",
    "        \n",
    "        for i in range(0,img.size[1]-1):\n",
    "            image_RGBA[i,0][3] = 0\n",
    "            image_RGBA[i,img.size[0]-1][3] = 0\n",
    "            \n",
    "        \n",
    "        \n",
    "        for border in borders:\n",
    "            image_RGBA[border[1],border[0]][3] = 0\n",
    "            \n",
    "        \n",
    "        head, tail = ntpath.split(image_path)\n",
    "        \n",
    "        title,extension = tail.split('.')\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Processed_Images/\"+title+\".png\", image_RGBA)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = 'Traffic_Signs_Templates/Images'\n",
    "if (not os.path.exists(\"Traffic_Signs_Templates/Processed_Images\")):\n",
    "    os.mkdir(\"Traffic_Signs_Templates/Processed_Images\")\n",
    "paths = load_paths(directory)\n",
    "manipulate_images(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_transform(paths):\n",
    "    \n",
    "    for image_path in paths:\n",
    "        \n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        rows,cols,ch = img.shape\n",
    "        t = []\n",
    "        for i in range(0,100):\n",
    "            t.append(i)\n",
    "            \n",
    "        #FORWARD FACING\n",
    "        dst = img\n",
    "        \n",
    "        #EAST FACING\n",
    "        pts1 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols/10,rows/2]])\n",
    "        pts2 = np.float32([[cols/5,rows/5],[cols/2,rows/8],[cols/5,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts1,pts2)\n",
    "        dst1 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #NORTH-WEST FACING\n",
    "        pts3 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts4 = np.float32([[cols*4.5/5,rows/5],[cols/2,rows/8],[cols*4.5/5,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts3,pts4)\n",
    "        dst2 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #LEFT TILTED FORWARD FACING\n",
    "        pts5 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols/10,rows/2]])\n",
    "        pts6 = np.float32([[cols/12,rows/6],[cols/2.1,rows/8],[cols/10,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts5,pts6)\n",
    "        dst3 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #RIGHT TILTED FORWARD FACING\n",
    "        pts7 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts8 = np.float32([[cols*10/12,rows/6],[cols/2.2,rows/8],[cols*8.4/10,rows/1.8]])\n",
    "        M = cv2.getAffineTransform(pts7,pts8)\n",
    "        dst4 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #WEST FACING\n",
    "        pts9 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts10 = np.float32([[cols/9.95,rows/10],[cols/2.05,rows/9.95],[cols*9/10,rows/2.05]])\n",
    "        M = cv2.getAffineTransform(pts9,pts10)\n",
    "        dst5 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #RIGHT TILTED FORWARD FACING\n",
    "        pts11 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts12 = np.float32([[cols*9/10,rows/10],[cols/2,rows/9],[cols*8.95/10,rows/2.05]])\n",
    "        M = cv2.getAffineTransform(pts11,pts12)\n",
    "        dst6 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION\n",
    "        pts13 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts14 = np.float32([[cols/9.8,rows/9.8],[cols/2,rows/9.8],[cols*8.8/10,rows/2.05]])\n",
    "        M = cv2.getAffineTransform(pts13,pts14)\n",
    "        dst7 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 2\n",
    "        pts15 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts16 = np.float32([[cols/11,rows/10],[cols/2.1,rows/10],[cols*8.5/10,rows/1.95]])\n",
    "        M = cv2.getAffineTransform(pts15,pts16)\n",
    "        dst8 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 3\n",
    "        pts17 = np.float32([[cols/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts18 = np.float32([[cols/11,rows/11],[cols/2.1,rows/10],[cols*10/11,rows/1.95]])\n",
    "        M = cv2.getAffineTransform(pts17,pts18)\n",
    "        dst9 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 4\n",
    "        pts19 = np.float32([[cols*9.5/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts20 = np.float32([[cols*9.35/10,rows/9.99],[cols/2.05,rows/9.95],[cols*9.05/10,rows/2.03]])\n",
    "        M = cv2.getAffineTransform(pts19,pts20)\n",
    "        dst10 = cv2.warpAffine(img,M,(cols,rows))\n",
    "         \n",
    "        #FORWARD FACING W/ DISTORTION 5\n",
    "        pts21 = np.float32([[cols*9.5/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts22 = np.float32([[cols*9.65/10,rows/9.95],[cols/1.95,rows/9.95],[cols*9.1/10,rows/2.02]])\n",
    "        M = cv2.getAffineTransform(pts21,pts22)\n",
    "        dst11 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 6\n",
    "        pts23 = np.float32([[cols*9.25/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts24 = np.float32([[cols*9.55/10,rows/9.85],[cols/1.9,rows/10],[cols*9.3/10,rows/2.04]])\n",
    "        M = cv2.getAffineTransform(pts23,pts24)\n",
    "        dst12 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #SHRINK 1\n",
    "        pts25 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts26 = np.float32([[cols*8/10,rows/10],[cols*1.34/3,rows/10.5],[cols*8.24/10,rows/2.5]])\n",
    "        M = cv2.getAffineTransform(pts25,pts26)\n",
    "        dst13 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #SHRINK 2\n",
    "        pts27 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts28 = np.float32([[cols*8.5/10,rows*3.1/10],[cols/2,rows*3/10],[cols*8.44/10,rows*1.55/2.5]])\n",
    "        M = cv2.getAffineTransform(pts27,pts28)\n",
    "        dst14 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 7\n",
    "        pts29 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts30 = np.float32([[cols*8.85/10,rows/9.3],[cols/1.9,rows/10.5],[cols*8.8/10,rows/2.11]])\n",
    "        M = cv2.getAffineTransform(pts29,pts30)\n",
    "        dst15 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 8\n",
    "        pts31 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts32 = np.float32([[cols*8.75/10,rows/9.1],[cols/1.95,rows/8],[cols*8.5/10,rows/2.05]])\n",
    "        M = cv2.getAffineTransform(pts31,pts32)\n",
    "        dst16 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 9\n",
    "        pts33 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts34 = np.float32([[cols*8.75/10,rows/9.1],[cols/1.95,rows/9],[cols*8.5/10,rows/2.2]])\n",
    "        M = cv2.getAffineTransform(pts33,pts34)\n",
    "        dst17 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 10\n",
    "        pts35 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts36 = np.float32([[cols*8.75/10,rows/8],[cols/1.95,rows/8],[cols*8.75/10,rows/2]])\n",
    "        M = cv2.getAffineTransform(pts35,pts36)\n",
    "        dst18 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        \n",
    "        #FORWARD FACING W/ DISTORTION 11\n",
    "        pts37 = np.float32([[cols*9/10,rows/10],[cols/2,rows/10],[cols*9/10,rows/2]])\n",
    "        pts38 = np.float32([[cols*8.8/10,rows/7],[cols/1.95,rows/7],[cols*8.8/10,rows/2]])\n",
    "        M = cv2.getAffineTransform(pts37,pts38)\n",
    "        dst19 = cv2.warpAffine(img,M,(cols,rows))\n",
    "        \n",
    "        head, tail = ntpath.split(image_path)\n",
    "        \n",
    "        title,extension = tail.split('.')\n",
    "        \n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[0])+\".png\",dst)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[1])+\".png\",dst1)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[2])+\".png\",dst2)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[3])+\".png\",dst3)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[4])+\".png\",dst4)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[5])+\".png\",dst5)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[6])+\".png\",dst6)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[7])+\".png\",dst7)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[8])+\".png\",dst8)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[9])+\".png\",dst9)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[10])+\".png\",dst10)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[11])+\".png\",dst11)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[12])+\".png\",dst12)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[13])+\".png\",dst13)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[14])+\".png\",dst14)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[15])+\".png\",dst15)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[16])+\".png\",dst16)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[17])+\".png\",dst17)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[18])+\".png\",dst18)\n",
    "        cv2.imwrite(\"Traffic_Signs_Templates/Transformed_Images/\"+title+\"/\"+str(t[19])+\".png\",dst19)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = 'Traffic_Signs_Templates/Processed_Images'\n",
    "if (not os.path.exists(\"Traffic_Signs_Templates/Transformed_Images\")):\n",
    "    for path in paths:\n",
    "        head, tail = ntpath.split(path)    \n",
    "        title,extension = tail.split('.')\n",
    "        os.makedirs(\"Traffic_Signs_Templates/Transformed_Images/\"+title)\n",
    "paths = load_paths(directory)\n",
    "img_transform(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_image_exposure(paths,channels):\n",
    "    \n",
    "    exposures = []\n",
    "    \n",
    "    for image_path in paths:\n",
    "        img = Image.open(image_path)\n",
    "        im = Image.open(image_path).convert('LA')\n",
    "        \n",
    "        stat = ImageStat.Stat(im)\n",
    "        \n",
    "        #Average pixel brighness\n",
    "        avg = stat.mean[0]\n",
    "        \n",
    "        #RMS pixel brighness\n",
    "        rms = stat.rms[0]\n",
    "        \n",
    "        stat2 = ImageStat.Stat(img)\n",
    "        \n",
    "        #Consider the number of channels\n",
    "        #background may have RGB while traffic sign has RGBA\n",
    "        if (channels==3):\n",
    "            #Average pixels preceived brightness\n",
    "            r,g,b = stat2.mean\n",
    "            avg_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))\n",
    "\n",
    "            #RMS pixels perceived brightness\n",
    "            r,g,b = stat2.rms\n",
    "            rms_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2)) \n",
    "\n",
    "            l = [image_path,avg,rms,avg_perceived,rms_perceived]\n",
    "            exposures.append(l)\n",
    "        else:\n",
    "            #Average pixels preceived brightness\n",
    "            r,g,b,a = stat2.mean\n",
    "            avg_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))\n",
    "\n",
    "            #RMS pixels perceived brightness\n",
    "            r,g,b,a = stat2.rms\n",
    "            rms_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2)) \n",
    "\n",
    "            l = [image_path,avg,rms,avg_perceived,rms_perceived]\n",
    "            exposures.append(l)\n",
    "             \n",
    "\n",
    "    return exposures     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_png(directory):\n",
    "    for files in load_paths(directory):\n",
    "        title,extension = files.split('.')\n",
    "        img = Image.open(files).convert('RGBA')\n",
    "        if (not extension == \"png\"):\n",
    "            os.remove(files)\n",
    "        img.save(title+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_png(\"Google_search_backgrounds/UK_urban\")\n",
    "to_png(\"Google_search_backgrounds/UK_rural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exposure_manipulation(signs_paths,backgrounds_paths):\n",
    "    \n",
    "    background_exposures = find_image_exposure(background_paths,4)\n",
    "    signs_exposures = find_image_exposure(signs_paths,4)\n",
    "    \n",
    "    for i in range(0,len(background_paths)):\n",
    "        \n",
    "        print \"Processed: \"+str(float(i)/float(len(background_paths))*100)+\" %\"\n",
    "        \n",
    "        img = Image.open(background_exposures[i][0])\n",
    "\n",
    "\n",
    "        for sign_path in signs_paths:\n",
    "\n",
    "            dirc,sub,el = background_exposures[i][0].split('/')\n",
    "            title,extension = el.split('.')\n",
    "\n",
    "            parent_dir,sub_dir,folder,element = sign_path.split('/')\n",
    "            head,tail = element.split('.')\n",
    "\n",
    "            brightness_avrg = 1.0\n",
    "            brightness_rms = 1.0\n",
    "            brightness_avrg_perceived = 1.0\n",
    "            brightness_rms_perceived = 1.0\n",
    "            brightness_avrg2 = 1.0\n",
    "            brightness_rms2 = 1.0\n",
    "            \n",
    "            # abs(desired_brightness - actual_brightness)/ abs(brightness_float_value) = ratio\n",
    "            avrg_ratio = 11.0159464507\n",
    "\n",
    "            rms_ratio = 8.30320014372\n",
    "\n",
    "            percieved_avrg_ratio = 3.85546373056\n",
    "\n",
    "            percieved_rms_ratio = 35.6344530649\n",
    "\n",
    "            avrg2_ratio = 1.20354549572\n",
    "\n",
    "            rms2_ratio = 40.1209106864\n",
    "\n",
    "            peak = Image.open(sign_path).convert('LA')\n",
    "            peak2 = Image.open(sign_path).convert('RGBA')\n",
    "\n",
    "            stat = ImageStat.Stat(peak)\n",
    "            avrg = stat.mean[0]\n",
    "            rms = stat.rms[0]\n",
    "\n",
    "            #IMAGE MANIPULATION MAIN CODE STARTS\n",
    "\n",
    "            #MINIMISE MARGIN BASED ON AVERAGE FOR TWO CHANNEL BRIGNESS VARIATION\n",
    "            margin = abs(avrg-float(background_exposures[i][1]))\n",
    "            \n",
    "            brightness_avrg = margin/avrg_ratio \n",
    "            \n",
    "            enhancer = ImageEnhance.Brightness(peak2)\n",
    "            avrg_bright = enhancer.enhance(brightness_avrg)\n",
    "            stat = ImageStat.Stat(avrg_bright)\n",
    "            avrg = stat.mean[0]\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            #MINIMISE MARGIN BASED ON ROOT MEAN SQUARE FOR TWO CHANNEL BRIGNESS VARIATION\n",
    "            margin = abs(rms-float(background_exposures[i][2]))\n",
    "\n",
    "            brightness_rms = margin/rms_ratio \n",
    "            \n",
    "            enhancer = ImageEnhance.Brightness(peak2)\n",
    "            rms_bright = enhancer.enhance(brightness_rms)\n",
    "            stat = ImageStat.Stat(rms_bright)\n",
    "            rms = stat.rms[0]\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #MINIMISE MARGIN BASED ON AVERAGE FOR RGBA (\"PERCEIVED BRIGHNESS\")\n",
    "            #REFERENCE FOR ALGORITHM USED: http://alienryderflex.com/hsp.html\n",
    "            stat2 = ImageStat.Stat(peak2)\n",
    "\n",
    "            r,g,b,a = stat2.mean\n",
    "            avrg_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))\n",
    "            margin = abs(avrg_perceived-float(background_exposures[i][3]))\n",
    "            \n",
    "            brightness_avrg_perceived = margin/percieved_avrg_ratio \n",
    "            \n",
    "            enhancer = ImageEnhance.Brightness(peak2)\n",
    "            avrg_bright_perceived = enhancer.enhance(brightness_avrg_perceived)\n",
    "            stat2 = ImageStat.Stat(avrg_bright_perceived)\n",
    "            r,g,b,a = stat2.mean\n",
    "            avrg_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))        \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            #MINIMISE MARGIN BASED ON RMS FOR RGBA (\"PERCEIVED BRIGHNESS\")\n",
    "            #REFERENCE FOR ALGORITHM USED: http://alienryderflex.com/hsp.html\n",
    "            r,g,b,a = stat2.rms\n",
    "            rms_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))\n",
    "\n",
    "            margin = abs(rms_perceived-float(background_exposures[i][4]))\n",
    "\n",
    "            brightness_rms_perceived = margin/percieved_rms_ratio \n",
    "\n",
    "            enhancer = ImageEnhance.Brightness(peak2)\n",
    "            rms_bright_perceived = enhancer.enhance(brightness_rms_perceived)\n",
    "            stat2 = ImageStat.Stat(rms_bright_perceived)\n",
    "            r,g,b,a = stat2.rms\n",
    "            rms_perceived = math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))        \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            stat3 = ImageStat.Stat(peak2)\n",
    "            avrg2 = stat3.mean[0]\n",
    "            rms2 = stat3.rms[0]\n",
    "\n",
    "\n",
    "            #FUSION OF THE TWO AVERAGING METHODS\n",
    "            margin = abs(avrg2-float(background_exposures[i][1]))\n",
    "\n",
    "            brightness_avrg2 = margin/avrg2_ratio \n",
    "    \n",
    "            enhancer = ImageEnhance.Brightness(peak2)\n",
    "            avrg_bright2 = enhancer.enhance(brightness_avrg2)\n",
    "            stat3 = ImageStat.Stat(avrg_bright2)\n",
    "            avrg2 = stat3.mean[0]       \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            #FUSION OF THE TWO RMS METHODS\n",
    "            margin = abs(rms2-float(background_exposures[i][2]))\n",
    "            \n",
    "            brightness_rms2 = margin/rms2_ratio \n",
    "            \n",
    "            enhancer = ImageEnhance.Brightness(peak2)\n",
    "            rms_bright2 = enhancer.enhance(brightness_rms2)\n",
    "            stat3 = ImageStat.Stat(rms_bright2)\n",
    "            rms2 = stat3.rms[0]        \n",
    "            \n",
    "            avrg_bright = avrg_bright.resize((150,150), Image.ANTIALIAS)\n",
    "            rms_bright = rms_bright.resize((150,150), Image.ANTIALIAS)\n",
    "            avrg_bright_perceived = avrg_bright_perceived.resize((150,150), Image.ANTIALIAS)\n",
    "            rms_bright_perceived = rms_bright_perceived.resize((150,150), Image.ANTIALIAS)\n",
    "            avrg_bright2 = avrg_bright2.resize((150,150), Image.ANTIALIAS)\n",
    "            rms_bright2 = rms_bright2.resize((150,150), Image.ANTIALIAS)\n",
    "\n",
    "            \n",
    "            #avrg_bright.save(\"Traffic_Signs_exposure_manipulation/\"+sub+\"/\"+title+\"/SIGN_\"+folder+\"/\"+head+\"_AVERAGE.\"+tail)\n",
    "            rms_bright.save(\"Traffic_Signs_exposure_manipulation/\"+sub+\"/\"+title+\"/SIGN_\"+folder+\"/\"+head+\"_RMS.\"+tail)\n",
    "            #avrg_bright_perceived.save(\"Traffic_Signs_exposure_manipulation/\"+sub+\"/\"+title+\"/SIGN_\"+folder+\"/\"+head+\"_AVERAGE_PERCEIVED.\"+tail)\n",
    "            rms_bright_perceived.save(\"Traffic_Signs_exposure_manipulation/\"+sub+\"/\"+title+\"/SIGN_\"+folder+\"/\"+head+\"_RMS_PERCEIVED.\"+tail)\n",
    "            #avrg_bright2.save(\"Traffic_Signs_exposure_manipulation/\"+sub+\"/\"+title+\"/SIGN_\"+folder+\"/\"+head+\"_AVERAGE2.\"+tail)\n",
    "            rms_bright2.save(\"Traffic_Signs_exposure_manipulation/\"+sub+\"/\"+title+\"/SIGN_\"+folder+\"/\"+head+\"_RMS2.\"+tail)\n",
    "    print \"Processed: \"+str(100)+\" %\"\n",
    "    print \"Process was successful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0.0 %\n",
      "Processed: 1.25 %\n",
      "Processed: 2.5 %\n",
      "Processed: 3.75 %\n",
      "Processed: 5.0 %\n",
      "Processed: 6.25 %\n",
      "Processed: 7.5 %\n",
      "Processed: 8.75 %\n",
      "Processed: 10.0 %\n",
      "Processed: 11.25 %\n",
      "Processed: 12.5 %\n",
      "Processed: 13.75 %\n",
      "Processed: 15.0 %\n",
      "Processed: 16.25 %\n",
      "Processed: 17.5 %\n",
      "Processed: 18.75 %\n",
      "Processed: 20.0 %\n",
      "Processed: 21.25 %\n",
      "Processed: 22.5 %\n",
      "Processed: 23.75 %\n",
      "Processed: 25.0 %\n",
      "Processed: 26.25 %\n",
      "Processed: 27.5 %\n",
      "Processed: 28.75 %\n",
      "Processed: 30.0 %\n",
      "Processed: 31.25 %\n",
      "Processed: 32.5 %\n",
      "Processed: 33.75 %\n",
      "Processed: 35.0 %\n",
      "Processed: 36.25 %\n",
      "Processed: 37.5 %\n",
      "Processed: 38.75 %\n",
      "Processed: 40.0 %\n",
      "Processed: 41.25 %\n",
      "Processed: 42.5 %\n",
      "Processed: 43.75 %\n",
      "Processed: 45.0 %\n",
      "Processed: 46.25 %\n",
      "Processed: 47.5 %\n",
      "Processed: 48.75 %\n",
      "Processed: 50.0 %\n",
      "Processed: 51.25 %\n",
      "Processed: 52.5 %\n",
      "Processed: 53.75 %\n",
      "Processed: 55.0 %\n",
      "Processed: 56.25 %\n",
      "Processed: 57.5 %\n",
      "Processed: 58.75 %\n",
      "Processed: 60.0 %\n",
      "Processed: 61.25 %\n",
      "Processed: 62.5 %\n",
      "Processed: 63.75 %\n",
      "Processed: 65.0 %\n",
      "Processed: 66.25 %\n",
      "Processed: 67.5 %\n",
      "Processed: 68.75 %\n",
      "Processed: 70.0 %\n",
      "Processed: 71.25 %\n",
      "Processed: 72.5 %\n",
      "Processed: 73.75 %\n",
      "Processed: 75.0 %\n",
      "Processed: 76.25 %\n",
      "Processed: 77.5 %\n",
      "Processed: 78.75 %\n",
      "Processed: 80.0 %\n",
      "Processed: 81.25 %\n",
      "Processed: 82.5 %\n",
      "Processed: 83.75 %\n",
      "Processed: 85.0 %\n",
      "Processed: 86.25 %\n",
      "Processed: 87.5 %\n",
      "Processed: 88.75 %\n",
      "Processed: 90.0 %\n",
      "Processed: 91.25 %\n",
      "Processed: 92.5 %\n",
      "Processed: 93.75 %\n",
      "Processed: 95.0 %\n",
      "Processed: 96.25 %\n",
      "Processed: 97.5 %\n",
      "Processed: 98.75 %\n",
      "Processed: 100 %\n",
      "Process was successful\n"
     ]
    }
   ],
   "source": [
    "bg_dir = \"Google_search_backgrounds\"\n",
    "\n",
    "for dirs in load_paths(bg_dir):    \n",
    "    initial,subd = dirs.split('/')\n",
    "    \n",
    "    for background in load_paths(dirs):\n",
    "        initial,subd,element = background.split('/')\n",
    "        title,extension = element.split('.')\n",
    "        \n",
    "        for signp in load_paths(\"Traffic_Signs_Templates/Transformed_Images\"):\n",
    "            for sign in load_paths(signp):\n",
    "                d,s,f,e = sign.split('/')\n",
    "                head,tail = e.split('.')\n",
    "            \n",
    "                if (not os.path.exists(\"Traffic_Signs_exposure_manipulation/\"+subd+\"/\"+title+\"/SIGN_\"+f)):\n",
    "                    os.makedirs(\"Traffic_Signs_exposure_manipulation/\"+subd+\"/\"+title+\"/SIGN_\"+f)\n",
    "            \n",
    "\n",
    "signs_paths = []\n",
    "for p in load_paths(\"Traffic_Signs_Templates/Transformed_Images\"):\n",
    "    signs_paths = signs_paths + load_paths(p)\n",
    "\n",
    "background_paths = load_paths(\"Google_search_backgrounds/UK_urban\")\n",
    "exposure_manipulation(signs_paths,background_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0.0 %\n",
      "Processed: 1.25 %\n",
      "Processed: 2.5 %\n",
      "Processed: 3.75 %\n",
      "Processed: 5.0 %\n",
      "Processed: 6.25 %\n",
      "Processed: 7.5 %\n",
      "Processed: 8.75 %\n",
      "Processed: 10.0 %\n",
      "Processed: 11.25 %\n",
      "Processed: 12.5 %\n",
      "Processed: 13.75 %\n",
      "Processed: 15.0 %\n",
      "Processed: 16.25 %\n",
      "Processed: 17.5 %\n",
      "Processed: 18.75 %\n",
      "Processed: 20.0 %\n",
      "Processed: 21.25 %\n",
      "Processed: 22.5 %\n",
      "Processed: 23.75 %\n",
      "Processed: 25.0 %\n",
      "Processed: 26.25 %\n",
      "Processed: 27.5 %\n",
      "Processed: 28.75 %\n",
      "Processed: 30.0 %\n",
      "Processed: 31.25 %\n",
      "Processed: 32.5 %\n",
      "Processed: 33.75 %\n",
      "Processed: 35.0 %\n",
      "Processed: 36.25 %\n",
      "Processed: 37.5 %\n",
      "Processed: 38.75 %\n",
      "Processed: 40.0 %\n",
      "Processed: 41.25 %\n",
      "Processed: 42.5 %\n",
      "Processed: 43.75 %\n",
      "Processed: 45.0 %\n",
      "Processed: 46.25 %\n",
      "Processed: 47.5 %\n",
      "Processed: 48.75 %\n",
      "Processed: 50.0 %\n",
      "Processed: 51.25 %\n",
      "Processed: 52.5 %\n",
      "Processed: 53.75 %\n",
      "Processed: 55.0 %\n",
      "Processed: 56.25 %\n",
      "Processed: 57.5 %\n",
      "Processed: 58.75 %\n",
      "Processed: 60.0 %\n",
      "Processed: 61.25 %\n",
      "Processed: 62.5 %\n",
      "Processed: 63.75 %\n",
      "Processed: 65.0 %\n",
      "Processed: 66.25 %\n",
      "Processed: 67.5 %\n",
      "Processed: 68.75 %\n",
      "Processed: 70.0 %\n",
      "Processed: 71.25 %\n",
      "Processed: 72.5 %\n",
      "Processed: 73.75 %\n",
      "Processed: 75.0 %\n",
      "Processed: 76.25 %\n",
      "Processed: 77.5 %\n",
      "Processed: 78.75 %\n",
      "Processed: 80.0 %\n",
      "Processed: 81.25 %\n",
      "Processed: 82.5 %\n",
      "Processed: 83.75 %\n",
      "Processed: 85.0 %\n",
      "Processed: 86.25 %\n",
      "Processed: 87.5 %\n",
      "Processed: 88.75 %\n",
      "Processed: 90.0 %\n",
      "Processed: 91.25 %\n",
      "Processed: 92.5 %\n",
      "Processed: 93.75 %\n",
      "Processed: 95.0 %\n",
      "Processed: 96.25 %\n",
      "Processed: 97.5 %\n",
      "Processed: 98.75 %\n",
      "Processed: 100 %\n",
      "Process was successful\n"
     ]
    }
   ],
   "source": [
    "background_paths = load_paths(\"Google_search_backgrounds/UK_rural\")\n",
    "exposure_manipulation(signs_paths,background_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avrg_pixel_rgb(image,chanels):\n",
    "    stat = ImageStat.Stat(image)\n",
    "    if (chanels == 4):\n",
    "        r,g,b,a = stat.rms\n",
    "    else:\n",
    "        r,g,b = stat.rms\n",
    "    \n",
    "    return [r,g,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_bw_images(directory):\n",
    "    images = []\n",
    "    for signs in load_paths(directory):\n",
    "        img = Image.open(signs).convert('RGBA')\n",
    "        rgb = avrg_pixel_rgb(img,4)\n",
    "        rg = abs(rgb[0]-rgb[1])\n",
    "        rb = abs(rgb[0]-rgb[2])\n",
    "        gb = abs(rgb[1]-rgb[2])\n",
    "        \n",
    "        temp = signs.split('/')\n",
    "        head,tail = temp[-1].split('.')\n",
    "                \n",
    "        if (rg<=1 and rb<=1 and gb<=1):\n",
    "            images.append(head)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_useful_signs(directory):\n",
    "    bw_images = find_bw_images(\"Traffic_Signs_Templates/Images\")\n",
    "    for background_dir in load_paths(directory):\n",
    "        \n",
    "        for signs in load_paths(background_dir):\n",
    "            temp = []\n",
    "            for imgs in load_paths(signs):\n",
    "                temp.append(imgs)\n",
    "            exposures = find_image_exposure(temp,4)\n",
    "            i = 0\n",
    "            for images in load_paths(signs):\n",
    "                \n",
    "                \n",
    "                \n",
    "                #Find brightness\n",
    "                img = Image.open(images).convert('RGBA')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                rgb = avrg_pixel_rgb(img,4)\n",
    "                rg = abs(rgb[0]-rgb[1])\n",
    "                rb = abs(rgb[0]-rgb[2])\n",
    "                gb = abs(rgb[1]-rgb[2])\n",
    "                \n",
    "                    \n",
    "                is_bw = False\n",
    "                \n",
    "                for s in bw_images:\n",
    "                    if s in exposures[i][0]:\n",
    "                        is_bw = True\n",
    "                    \n",
    "                if (rg<=20 and rb<=20 and gb<=20 ):\n",
    "                    if (not is_bw):\n",
    "                        os.remove(images)\n",
    "                    elif (rgb[0]<70 and rgb[1]<70 and rgb[2]<70):\n",
    "                        os.remove(images)\n",
    "                    elif (rgb[0]>160 and rgb[1]>160 and rgb[2]>160):\n",
    "                        os.remove(images)\n",
    "                i = i+1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory= \"Traffic_Signs_exposure_manipulation/UK_urban\"\n",
    "find_useful_signs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory= \"Traffic_Signs_exposure_manipulation/UK_rural\"\n",
    "find_useful_signs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_poisson_noise (image):\n",
    "    vals = len(np.unique(image))\n",
    "    vals = 2.05 ** np.ceil(np.log2(vals))\n",
    "    noisy = np.random.poisson(image * vals) / float(vals)\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_Gaussian_noise (image):\n",
    "    row,col,ch= image.shape\n",
    "    mean = 0\n",
    "    var = 0.5\n",
    "    sigma = var**0.5\n",
    "    gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "    gauss = gauss.reshape(row,col,ch)\n",
    "    noisy = image + gauss\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_speckle_noise (image):\n",
    "    row,col,ch = image.shape\n",
    "    gauss = np.random.randn(row,col,ch)\n",
    "    gauss = gauss.reshape(row,col,ch)        \n",
    "    noisy = image + image * gauss\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_noise_method (image):\n",
    "    \"\"\"\n",
    "    i = random.randint(1, 3)\n",
    "    if (i == 1):\n",
    "        return insert_poisson_noise(image)\n",
    "    elif (i==2):\n",
    "        return insert_Gaussian_noise(image)\n",
    "    else:\n",
    "        return insert_speckle_noise(image)\n",
    "    \"\"\"\n",
    "    image.setflags(write=1)\n",
    "    #Add noise in every pixel w/ random probability 0.4\n",
    "    for im in image:\n",
    "        px = 0\n",
    "        for pixel in im:\n",
    "            apply_noise = random.randint(0,100)\n",
    "            #if random probability\n",
    "            if apply_noise > 40:\n",
    "                #RGB values\n",
    "                R = pixel[0]\n",
    "                G = pixel[1]\n",
    "                B = pixel[2]\n",
    "                A = pixel[3]\n",
    "                #find current relative lumination for brighness\n",
    "                #based on: https://en.wikipedia.org/wiki/Relative_luminance\n",
    "                relative_lumination = 0.2126*R + 0.7152*G + 0.0722*B\n",
    "                #find differences between RGB values     \n",
    "                R_to_G = float(R)/float(G)\n",
    "                RG = False\n",
    "                if (R_to_G >= 1): RG=True\n",
    "                R_to_B = float(R)/float(B)\n",
    "                RB = False\n",
    "                if (R_to_B >= 1): RB=True\n",
    "                G_to_B = float(G)/float(B)\n",
    "                GB = False\n",
    "                if (G_to_B >= 1): GB=True\n",
    "                equal = False\n",
    "                if (R==G==B):equal==True\n",
    "\n",
    "                #In order to determine the margin in which the new brighness\n",
    "                #should be within, the upper and lower limits need to be foun\n",
    "                #The Relative luminance in colorimetric spaces has normilised\n",
    "                #values between 0 and 255\n",
    "                upper_limit = 255\n",
    "                lower_limit = 0\n",
    "                if (relative_lumination + 40 < 255):\n",
    "                    upper_limit = relative_lumination + 40\n",
    "                if (relative_lumination - 40 > 0):\n",
    "                    lower_limit = relative_lumination - 40\n",
    "\n",
    "                #Compute new brighness value\n",
    "                new_lumination = random.randint(int(lower_limit),int(upper_limit))\n",
    "\n",
    "                #find the three possible solutions that satisfy\n",
    "                #->The new lumination chosen based on the Relative luminance equation\n",
    "                #->The precentages computed between every RGB value\n",
    "\n",
    "                solutions = []\n",
    "\n",
    "                for r in range(1,255):\n",
    "                    for g in range(1,255):\n",
    "                        for b in range(1,255):\n",
    "                            r_to_g = float(r)/float(g)\n",
    "                            rg = False\n",
    "                            if (r_to_g >= 1): rg=True\n",
    "                            r_to_b = float(r)/float(b)\n",
    "                            rb = False\n",
    "                            if (r_to_b >= 1): rb=True\n",
    "                            g_to_b = float(g)/float(b)\n",
    "                            gb = False\n",
    "                            if (g_to_b >= 1): gb=True\n",
    "                            e = False\n",
    "                            if(r==g==b):\n",
    "                                e=True\n",
    "                            if (0.2126*r + 0.7152*g + 0.0722*b == 100) and rg==RG and rb==RB and gb==GB and e==equal:\n",
    "                                solutions.append([r,g,b])\n",
    "\n",
    "                #Find the solution that precentage wise is closer to the original\n",
    "                #difference between the values\n",
    "                percentages = []\n",
    "\n",
    "                for solution in solutions:\n",
    "                    r = solution[0]\n",
    "                    g = solution[1]\n",
    "                    b = solution[2]\n",
    "                    percentages.append((float(r)/float(g))+(float(r)/float(b))+(float(g)/float(b)))\n",
    "\n",
    "                i = 0\n",
    "                pos = 0\n",
    "                best = percentages[0]\n",
    "                for p in percentages[1:]:\n",
    "                    if p < best:\n",
    "                        pos = i\n",
    "                    i = i +1\n",
    "\n",
    "                #Assign new pixel values\n",
    "                im[px] = [solutions[pos][0],solutions[pos][1],solutions[pos][2],A]\n",
    "            px = px+1\n",
    "            \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_data(image_dir,bg_dir):\n",
    "    \n",
    "    \n",
    "    # Import background image\n",
    "    background_img_raw = Image.open(bg_dir).convert('RGBA')  \n",
    "    background_img_raw = background_img_raw.resize((150,150), Image.ANTIALIAS)\n",
    "    background_img = np.array(background_img_raw)  \n",
    "    background_img_float = background_img.astype(float)  \n",
    "\n",
    "    # Import foreground image\n",
    "    foreground_img_raw = Image.open(image_dir)  \n",
    "    foreground_img = np.array(foreground_img_raw)  \n",
    "    foreground_img_float = foreground_img.astype(float)  \n",
    "\n",
    "    # Blend images\n",
    "    opacity = 1  \n",
    "    blended_img_float = blend_modes.grain_merge(background_img_float, foreground_img_float, opacity)\n",
    "\n",
    "    # Convert blended image back into PIL image\n",
    "    blended_img = np.uint8(blended_img_float)\n",
    "    blended_img_raw = Image.fromarray(blended_img)  \n",
    "    \n",
    "    foreground_img_raw = foreground_img_raw.resize((149,149), Image.ANTIALIAS)\n",
    "    blended_img_raw.paste(foreground_img_raw, (0, 0), foreground_img_raw)\n",
    "    blended_img_raw = blended_img_raw.resize((48,48), Image.ANTIALIAS)\n",
    "    \n",
    "    #temp = np.uint8(blended_img_raw)\n",
    "    #temp = random_noise_method(temp)\n",
    "    \n",
    "    #blended_img_raw = Image.fromarray(np.uint8(temp)) \n",
    "    \n",
    "    \n",
    "    return blended_img_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = 'SGTSD/Images'\n",
    "if (not os.path.exists(\"SGTSD/Images\")):\n",
    "    for sign in load_paths(\"Traffic_Signs_Templates/Images\"):\n",
    "        head,tail = sign.split('.')\n",
    "        name = []\n",
    "        name = head.split('/')\n",
    "        os.makedirs(\"SGTSD/Images/\"+name[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content = '''\n",
    "-----------------------------------------------\n",
    "|                     -*-                     |\n",
    "|Synthetically Generated Traffic Sign Dataset |\n",
    "|                     -*-                     |\n",
    "-----------------------------------------------\n",
    "\n",
    "This directory contains the training set for\n",
    "The Convolutional Neural Network (CNN)\n",
    "Used in this project\n",
    "\n",
    "However, it can be used for any classifier\n",
    "desired by the person using the code and\n",
    "additionally, it is not limited to a specific\n",
    "traffic sign templates.\n",
    " \n",
    "\n",
    "----------------------------------------------\n",
    "Content\n",
    "----------------------------------------------\n",
    "\n",
    "The number of example is based on the number:\n",
    "->of traffic signs that were used as templates\n",
    "->of the image manipulation processes\n",
    "->of the brighness variations values used\n",
    "->of the blending procedures\n",
    "\n",
    "\n",
    "----------------------------------------------\n",
    "Image format and naming\n",
    "----------------------------------------------\n",
    "The images created are of \"png\" format\n",
    "with RGBA channels\n",
    "\n",
    "   SIGN_X/XXX_YYY.png\n",
    "\n",
    "The initial part (X) is used to distinguish the\n",
    "sign class, while the remaining (XXX_YYY) firstly\n",
    "indicated the sign in the file itself and the\n",
    "example number.\n",
    "\n",
    "\n",
    "----------------------------------------------\n",
    "Additional information\n",
    "----------------------------------------------\n",
    "\n",
    "contact email: \n",
    "    \n",
    "\tasterga@essex.ac.uk\n",
    "\n",
    "\n",
    "----------------------------------------------\n",
    "Alexandros Stergiou\n",
    "\"The Driver's Assistant\"\n",
    "\n",
    "University of Essex,\n",
    "Schoolf of Computer Science and\n",
    "Electronic Engineering,\n",
    "UK\n",
    "----------------------------------------------\n",
    "'''\n",
    "text_file = open(\"SGTSD/Readme_Images.txt\", \"w\")\n",
    "text_file.write(content)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_paths_list(imgs_directory,bg_directory):\n",
    "    directories = []\n",
    "    for places in load_paths(imgs_directory):\n",
    "        for imgs in load_paths(places):\n",
    "            dr = []\n",
    "            dr = imgs.split('/')\n",
    "            bg = bg_directory +'/'+dr[-2]+'/'+dr[-1]+\".png\"\n",
    "            for signs in load_paths(imgs):\n",
    "                for png in load_paths(signs):\n",
    "                    directories.append([png,bg])\n",
    "    return directories\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files to be generated: 389724\n"
     ]
    }
   ],
   "source": [
    "directories = create_paths_list(\"Traffic_Signs_exposure_manipulation\",\"Google_search_backgrounds\")\n",
    "print \"Files to be generated: \"+str(len(directories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_for_sign_x(i,directories):\n",
    "    l = []\n",
    "    for elements in directories:\n",
    "        foreground = elements[0].split('/')\n",
    "        background = elements[1].split('/')\n",
    "        if (foreground[-2] == (\"SIGN_\"+str(i))):\n",
    "            l.append(elements)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_directories = []\n",
    "signs = load_paths('Traffic_Signs_Templates/Images')\n",
    "for i in range(0,len(signs)):\n",
    "    final_directories.append(list_for_sign_x(i,directories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0.0 %\n",
      "Processed: 2.0 %\n",
      "Processed: 4.0 %\n",
      "Processed: 6.0 %\n",
      "Processed: 8.0 %\n",
      "Processed: 10.0 %\n",
      "Processed: 12.0 %\n",
      "Processed: 14.0 %\n",
      "Processed: 16.0 %\n",
      "Processed: 18.0 %\n",
      "Processed: 20.0 %\n",
      "Processed: 22.0 %\n",
      "Processed: 24.0 %\n",
      "Processed: 26.0 %\n",
      "Processed: 28.0 %\n",
      "Processed: 30.0 %\n",
      "Processed: 32.0 %\n",
      "Processed: 34.0 %\n",
      "Processed: 36.0 %\n",
      "Processed: 38.0 %\n",
      "Processed: 40.0 %\n",
      "Processed: 42.0 %\n",
      "Processed: 44.0 %\n",
      "Processed: 46.0 %\n",
      "Processed: 48.0 %\n",
      "Processed: 50.0 %\n",
      "Processed: 52.0 %\n",
      "Processed: 54.0 %\n",
      "Processed: 56.0 %\n",
      "Processed: 58.0 %\n",
      "Processed: 60.0 %\n",
      "Processed: 62.0 %\n",
      "Processed: 64.0 %\n",
      "Processed: 66.0 %\n",
      "Processed: 68.0 %\n",
      "Processed: 70.0 %\n",
      "Processed: 72.0 %\n",
      "Processed: 74.0 %\n",
      "Processed: 76.0 %\n",
      "Processed: 78.0 %\n",
      "Processed: 80.0 %\n",
      "Processed: 82.0 %\n",
      "Processed: 84.0 %\n",
      "Processed: 86.0 %\n",
      "Processed: 88.0 %\n",
      "Processed: 90.0 %\n",
      "Processed: 92.0 %\n",
      "Processed: 94.0 %\n",
      "Processed: 96.0 %\n",
      "Processed: 98.0 %\n",
      "Processed: 100 %\n"
     ]
    }
   ],
   "source": [
    "direct = \"SGTSD/Images\"\n",
    "i = 0\n",
    "for element in final_directories:\n",
    "    print \"Processed: \"+str(float(i)/float(len(final_directories))*100)+\" %\"\n",
    "    j = 0\n",
    "    for dirs in element:\n",
    "        image = new_data(dirs[0],dirs[1])\n",
    "        image.save(direct+\"/\"+str(i)+\"/\"+str(i)+\"_\"+str(j)+\".png\")\n",
    "        j = j+1\n",
    "    i = i+1\n",
    "print \"Processed: \"+str(100)+\" %\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(\"Traffic_Signs_exposure_manipulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(\"Traffic_Signs_Templates/Transformed_Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(\"Traffic_Signs_Templates/Processed_Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string = '''\n",
    "-------------------------------------\n",
    "BREAKDOWN OF FILES GENERATED BY CLASS\n",
    "-------------------------------------\n",
    "'''\n",
    "total = 0\n",
    "for i in range (0,len(final_directories)):\n",
    "    s = \"Generated \"+str(len(final_directories[i]))+\" examples for sign class \"+str(i+1)\n",
    "    string = string + '\\n'+s+'\\n'\n",
    "    total = total + len(final_directories[i])\n",
    "string = string + '\\n'+\"TOTAL: \"+str(total)+'\\n'+\"Generated on: \"+datetime.now().strftime(\"%Y-%m-%d %H:%M\")+'\\n'\n",
    "string = string + \"-------------------------------------\"\n",
    "text_file = open(\"SGTSD/generated_images_about.txt\", \"w\")\n",
    "text_file.write(string)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def png_to_jpeg(filepath):\n",
    "    dirs = filepath.split('/')\n",
    "    title,extension = dirs[-1].split('.')\n",
    "    del dirs[-1]\n",
    "    string = '/'.join(dirs)\n",
    "    string = string+'/'+title+\".jpg\"\n",
    "    png = Image.open(filepath)\n",
    "    png.load() # required for png.split()\n",
    "    background = Image.new(\"RGB\", png.size, (255, 255, 255))\n",
    "    background.paste(png, mask=png.split()[3]) # 3 is the alpha channel\n",
    "    background.save(string, 'JPEG', quality=100)\n",
    "    os.remove(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0.0 %\n",
      "Processed: 2.0 %\n",
      "Processed: 4.0 %\n",
      "Processed: 6.0 %\n",
      "Processed: 8.0 %\n",
      "Processed: 10.0 %\n",
      "Processed: 12.0 %\n",
      "Processed: 14.0 %\n",
      "Processed: 16.0 %\n",
      "Processed: 18.0 %\n",
      "Processed: 20.0 %\n",
      "Processed: 22.0 %\n",
      "Processed: 24.0 %\n",
      "Processed: 26.0 %\n",
      "Processed: 28.0 %\n",
      "Processed: 30.0 %\n",
      "Processed: 32.0 %\n",
      "Processed: 34.0 %\n",
      "Processed: 36.0 %\n",
      "Processed: 38.0 %\n",
      "Processed: 40.0 %\n",
      "Processed: 42.0 %\n",
      "Processed: 44.0 %\n",
      "Processed: 46.0 %\n",
      "Processed: 48.0 %\n",
      "Processed: 50.0 %\n",
      "Processed: 52.0 %\n",
      "Processed: 54.0 %\n",
      "Processed: 56.0 %\n",
      "Processed: 58.0 %\n",
      "Processed: 60.0 %\n",
      "Processed: 62.0 %\n",
      "Processed: 64.0 %\n",
      "Processed: 66.0 %\n",
      "Processed: 68.0 %\n",
      "Processed: 70.0 %\n",
      "Processed: 72.0 %\n",
      "Processed: 74.0 %\n",
      "Processed: 76.0 %\n",
      "Processed: 78.0 %\n",
      "Processed: 80.0 %\n",
      "Processed: 82.0 %\n",
      "Processed: 84.0 %\n",
      "Processed: 86.0 %\n",
      "Processed: 88.0 %\n",
      "Processed: 90.0 %\n",
      "Processed: 92.0 %\n",
      "Processed: 94.0 %\n",
      "Processed: 96.0 %\n",
      "Processed: 98.0 %\n",
      "Processed: 100 %\n"
     ]
    }
   ],
   "source": [
    "dirs = direct = \"SGTSD/Images\"\n",
    "i = 1\n",
    "for path in load_paths(dirs):\n",
    "    print \"Processed: \"+str(float(i-1)/float(len(final_directories))*100)+\" %\"\n",
    "    for image in load_paths(path):\n",
    "        if (image.endswith(\"png\")):\n",
    "            png_to_jpeg(image)\n",
    "    i = i+1\n",
    "print \"Processed: \"+str(100)+\" %\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
